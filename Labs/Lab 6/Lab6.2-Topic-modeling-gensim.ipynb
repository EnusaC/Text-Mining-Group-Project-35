{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrate how LDA models can be built and applied using the *gensim* package.\n",
    "\n",
    "Credits:\n",
    "\n",
    "This notebook is an adaptation of a blog from Susan Li's:\n",
    "\n",
    "https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set we’ll use is a list of over one million news headlines published over a period of 15 years and can be downloaded from:\n",
    "\n",
    "https://www.kaggle.com/therohk/million-headlines/data\n",
    "\n",
    "You can also find this file in the lab6 folder.\n",
    "\n",
    "We read the CSV file using the pandas framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#### Adapt the path below to point to your local copy of the data set\n",
    "data = pd.read_csv('abcnews-date-text.csv', on_bad_lines=\"warn\");\n",
    "data_text = data[['headline_text']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mdocuments\u001b[49m))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(documents[:\u001b[38;5;241m5\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'documents' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(documents))\n",
    "print(documents[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the *gensim* package to build our LDA models from the data.\n",
    "Before building the model, we are going to preprocess the texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "We will perform the following steps:\n",
    "\n",
    "* Tokenization: Split the text into sentences and the sentences into words. Lowercase the words and remove punctuation.\n",
    "* Words that have fewer than 3 characters are removed.\n",
    "* All stopwords are removed.\n",
    "* Words are lemmatized — words in third person are changed to first person and verbs in past and future tenses are changed into present.\n",
    "* Words are stemmed — words are reduced to their root form.\n",
    "\n",
    "In order to apply these processing steps, we first load the gensim and nltk libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\camis/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return lemmatizer.lemmatize(text)\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "           # result.append(token)\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['ratepayers', 'group', 'wants', 'compulsory', 'local', 'govt', 'voting']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['ratepayer', 'group', 'want', 'compulsory', 'local', 'govt', 'voting']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the preprocessing to all the headlines and print the first 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [decides, community, broadcasting, licence]\n",
       "1                         [witness, aware, defamation]\n",
       "2           [call, infrastructure, protection, summit]\n",
       "3                          [staff, aust, strike, rise]\n",
       "4              [strike, affect, australian, traveller]\n",
       "5               [ambitious, olsson, win, triple, jump]\n",
       "6          [antic, delighted, record, breaking, barca]\n",
       "7    [aussie, qualifier, stosur, waste, memphis, ma...\n",
       "8             [aust, address, security, council, iraq]\n",
       "9                       [australia, locked, timetable]\n",
       "Name: headline_text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = documents['headline_text'].map(preprocess)\n",
    "### print the first 10 results\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words on the Data set\n",
    "Create a dictionary from ‘processed_docs’ containing the number of times a word appears in the training set.\n",
    "We are going to use the *Dictionary* function to derive a dictionary with counts from the headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 broadcasting\n",
      "1 community\n",
      "2 decides\n",
      "3 licence\n",
      "4 aware\n",
      "5 defamation\n",
      "6 witness\n",
      "7 call\n",
      "8 infrastructure\n",
      "9 protection\n",
      "10 summit\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim filter_extremes\n",
    "Filter out tokens that appear in\n",
    "less than 15 documents (absolute number) or\n",
    "more than 0.5 documents (fraction of total corpus size, not absolute number).\n",
    "after the above two steps, keep only the first 100000 most frequent tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim doc2bow\n",
    "For each document we create a dictionary reporting how many words and how many times those words appear. \n",
    "Gensim provides the *doc2bow* function to create a BoW vector representation for a document.\n",
    "Save this to ‘bow_corpus’, then check our selected document earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(164, 1), (241, 1), (615, 1), (891, 1), (4175, 1), (4176, 1), (4177, 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[4310]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview Bag Of Words for our sample preprocessed document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 164 (\"govt\") appears 1 time.\n",
      "Word 241 (\"group\") appears 1 time.\n",
      "Word 615 (\"local\") appears 1 time.\n",
      "Word 891 (\"want\") appears 1 time.\n",
      "Word 4175 (\"compulsory\") appears 1 time.\n",
      "Word 4176 (\"ratepayer\") appears 1 time.\n",
      "Word 4177 (\"voting\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_4310 = bow_corpus[4310]\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                               dictionary[bow_doc_4310[i][0]], \n",
    "bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "Create tf-idf model object using models.TfidfModel on ‘bow_corpus’ and save it to ‘tfidf’, then apply transformation to the entire corpus and call it ‘corpus_tfidf’. Finally we preview TF-IDF scores for our first document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.6161125947380649),\n",
      " (1, 0.3308772069039591),\n",
      " (2, 0.5681053683635203),\n",
      " (3, 0.43379930266554434)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LDA using Bag of Words\n",
    "Train our lda model using gensim.models.LdaMulticore and save it to ‘lda_model’. This takes a while.\n",
    "Look at the documentation of *gensim* for further details:\n",
    "\n",
    "https://radimrehurek.com/gensim/models/ldamulticore.html\n",
    "\n",
    "As parameters, we pass the corpus data as BoW (a list of lists of tuples), the prefixed number of topics, the actual words and the number of passes and workers used for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each topic, we will explore the words occuring in that topic and its relative weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.034*\"case\" + 0.025*\"court\" + 0.023*\"police\" + 0.021*\"woman\" + 0.019*\"child\" + 0.018*\"vaccine\" + 0.017*\"murder\" + 0.015*\"death\" + 0.014*\"charged\" + 0.014*\"face\"\n",
      "Topic: 1 \n",
      "Words: 0.037*\"police\" + 0.024*\"school\" + 0.015*\"family\" + 0.014*\"missing\" + 0.013*\"guilty\" + 0.011*\"drum\" + 0.010*\"announces\" + 0.010*\"search\" + 0.010*\"help\" + 0.010*\"northern\"\n",
      "Topic: 2 \n",
      "Words: 0.019*\"victorian\" + 0.014*\"premier\" + 0.013*\"claim\" + 0.013*\"time\" + 0.012*\"speaks\" + 0.012*\"hotel\" + 0.012*\"pandemic\" + 0.011*\"road\" + 0.010*\"say\" + 0.009*\"black\"\n",
      "Topic: 3 \n",
      "Words: 0.023*\"government\" + 0.020*\"coast\" + 0.017*\"national\" + 0.016*\"live\" + 0.015*\"plan\" + 0.015*\"federal\" + 0.012*\"gold\" + 0.012*\"care\" + 0.012*\"farmer\" + 0.010*\"aged\"\n",
      "Topic: 4 \n",
      "Words: 0.060*\"covid\" + 0.044*\"coronavirus\" + 0.019*\"open\" + 0.016*\"melbourne\" + 0.016*\"lockdown\" + 0.014*\"dy\" + 0.014*\"sydney\" + 0.014*\"final\" + 0.012*\"hospital\" + 0.012*\"crash\"\n",
      "Topic: 5 \n",
      "Words: 0.029*\"election\" + 0.023*\"health\" + 0.018*\"people\" + 0.017*\"say\" + 0.017*\"minister\" + 0.015*\"change\" + 0.014*\"morrison\" + 0.012*\"labor\" + 0.012*\"andrew\" + 0.011*\"country\"\n",
      "Topic: 6 \n",
      "Words: 0.039*\"trump\" + 0.037*\"queensland\" + 0.032*\"victoria\" + 0.021*\"news\" + 0.020*\"record\" + 0.018*\"coronavirus\" + 0.017*\"market\" + 0.014*\"south\" + 0.012*\"brisbane\" + 0.011*\"australian\"\n",
      "Topic: 7 \n",
      "Words: 0.028*\"home\" + 0.021*\"tasmania\" + 0.018*\"business\" + 0.015*\"royal\" + 0.014*\"return\" + 0.012*\"commission\" + 0.012*\"power\" + 0.012*\"fight\" + 0.010*\"town\" + 0.009*\"perth\"\n",
      "Topic: 8 \n",
      "Words: 0.078*\"australia\" + 0.024*\"donald\" + 0.017*\"restriction\" + 0.014*\"coronavirus\" + 0.013*\"world\" + 0.011*\"australian\" + 0.010*\"climate\" + 0.010*\"win\" + 0.010*\"attack\" + 0.009*\"high\"\n",
      "Topic: 9 \n",
      "Words: 0.019*\"border\" + 0.017*\"north\" + 0.014*\"china\" + 0.014*\"protest\" + 0.013*\"west\" + 0.011*\"amid\" + 0.011*\"say\" + 0.011*\"president\" + 0.009*\"biden\" + 0.009*\"student\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you distinguish different topics using the words in each topic and their corresponding weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LDA using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.029*\"trump\" + 0.017*\"donald\" + 0.011*\"lockdown\" + 0.009*\"care\" + 0.007*\"aged\" + 0.007*\"election\" + 0.007*\"coronavirus\" + 0.006*\"korea\" + 0.006*\"say\" + 0.005*\"august\"\n",
      "Topic: 1 Word: 0.018*\"interview\" + 0.015*\"live\" + 0.015*\"vaccine\" + 0.009*\"speaks\" + 0.008*\"video\" + 0.007*\"peter\" + 0.007*\"extended\" + 0.007*\"daniel\" + 0.006*\"john\" + 0.006*\"july\"\n",
      "Topic: 2 Word: 0.015*\"news\" + 0.012*\"coronavirus\" + 0.011*\"market\" + 0.009*\"rural\" + 0.009*\"drum\" + 0.008*\"restriction\" + 0.007*\"victoria\" + 0.007*\"covid\" + 0.007*\"climate\" + 0.006*\"story\"\n",
      "Topic: 3 Word: 0.019*\"covid\" + 0.016*\"coronavirus\" + 0.008*\"update\" + 0.007*\"biden\" + 0.007*\"quarantine\" + 0.006*\"social\" + 0.006*\"case\" + 0.006*\"australia\" + 0.006*\"outback\" + 0.005*\"university\"\n",
      "Topic: 4 Word: 0.009*\"friday\" + 0.008*\"sport\" + 0.006*\"australia\" + 0.006*\"october\" + 0.006*\"territory\" + 0.005*\"quiz\" + 0.005*\"data\" + 0.005*\"asylum\" + 0.005*\"drone\" + 0.005*\"northern\"\n",
      "Topic: 5 Word: 0.013*\"border\" + 0.008*\"christmas\" + 0.008*\"coronavirus\" + 0.008*\"david\" + 0.007*\"state\" + 0.006*\"liberal\" + 0.006*\"testing\" + 0.006*\"facebook\" + 0.005*\"queensland\" + 0.005*\"say\"\n",
      "Topic: 6 Word: 0.011*\"morrison\" + 0.011*\"royal\" + 0.011*\"scott\" + 0.010*\"gold\" + 0.008*\"coast\" + 0.008*\"commission\" + 0.005*\"mount\" + 0.005*\"australia\" + 0.004*\"rollout\" + 0.004*\"sunday\"\n",
      "Topic: 7 Word: 0.017*\"country\" + 0.012*\"hour\" + 0.008*\"wednesday\" + 0.008*\"queensland\" + 0.008*\"mental\" + 0.007*\"health\" + 0.007*\"turnbull\" + 0.006*\"energy\" + 0.006*\"farm\" + 0.006*\"june\"\n",
      "Topic: 8 Word: 0.011*\"australia\" + 0.010*\"final\" + 0.010*\"world\" + 0.008*\"league\" + 0.007*\"test\" + 0.007*\"australian\" + 0.006*\"cricket\" + 0.006*\"beat\" + 0.006*\"alan\" + 0.006*\"open\"\n",
      "Topic: 9 Word: 0.017*\"police\" + 0.012*\"crash\" + 0.011*\"woman\" + 0.010*\"murder\" + 0.010*\"charged\" + 0.009*\"death\" + 0.008*\"missing\" + 0.007*\"court\" + 0.007*\"dead\" + 0.006*\"shooting\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, can you distinguish different topics using the words in each topic and their corresponding weights? Do you observe any differences with the BoW version? Do these differences make sense given the information value weighing by the *tfidf* method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation by classifying sample document using LDA Bag of Words model\n",
    "We will check where our test document would be classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ratepayer', 'group', 'want', 'compulsory', 'local', 'govt', 'voting']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[4310]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document 4310 is already represented in the correct way. We can directly pass it to our *lda_model* to get the similarity scores for each topic. We represent each topic by printing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.40326443314552307\t \n",
      "Topic: 0.023*\"government\" + 0.020*\"coast\" + 0.017*\"national\" + 0.016*\"live\" + 0.015*\"plan\" + 0.015*\"federal\" + 0.012*\"gold\" + 0.012*\"care\" + 0.012*\"farmer\" + 0.010*\"aged\"\n",
      "\n",
      "Score: 0.2624225616455078\t \n",
      "Topic: 0.039*\"trump\" + 0.037*\"queensland\" + 0.032*\"victoria\" + 0.021*\"news\" + 0.020*\"record\" + 0.018*\"coronavirus\" + 0.017*\"market\" + 0.014*\"south\" + 0.012*\"brisbane\" + 0.011*\"australian\"\n",
      "\n",
      "Score: 0.24675659835338593\t \n",
      "Topic: 0.029*\"election\" + 0.023*\"health\" + 0.018*\"people\" + 0.017*\"say\" + 0.017*\"minister\" + 0.015*\"change\" + 0.014*\"morrison\" + 0.012*\"labor\" + 0.012*\"andrew\" + 0.011*\"country\"\n",
      "\n",
      "Score: 0.0125083914026618\t \n",
      "Topic: 0.028*\"home\" + 0.021*\"tasmania\" + 0.018*\"business\" + 0.015*\"royal\" + 0.014*\"return\" + 0.012*\"commission\" + 0.012*\"power\" + 0.012*\"fight\" + 0.010*\"town\" + 0.009*\"perth\"\n",
      "\n",
      "Score: 0.012508370913565159\t \n",
      "Topic: 0.019*\"border\" + 0.017*\"north\" + 0.014*\"china\" + 0.014*\"protest\" + 0.013*\"west\" + 0.011*\"amid\" + 0.011*\"say\" + 0.011*\"president\" + 0.009*\"biden\" + 0.009*\"student\"\n",
      "\n",
      "Score: 0.012508335523307323\t \n",
      "Topic: 0.019*\"victorian\" + 0.014*\"premier\" + 0.013*\"claim\" + 0.013*\"time\" + 0.012*\"speaks\" + 0.012*\"hotel\" + 0.012*\"pandemic\" + 0.011*\"road\" + 0.010*\"say\" + 0.009*\"black\"\n",
      "\n",
      "Score: 0.012507826089859009\t \n",
      "Topic: 0.034*\"case\" + 0.025*\"court\" + 0.023*\"police\" + 0.021*\"woman\" + 0.019*\"child\" + 0.018*\"vaccine\" + 0.017*\"murder\" + 0.015*\"death\" + 0.014*\"charged\" + 0.014*\"face\"\n",
      "\n",
      "Score: 0.012507826089859009\t \n",
      "Topic: 0.037*\"police\" + 0.024*\"school\" + 0.015*\"family\" + 0.014*\"missing\" + 0.013*\"guilty\" + 0.011*\"drum\" + 0.010*\"announces\" + 0.010*\"search\" + 0.010*\"help\" + 0.010*\"northern\"\n",
      "\n",
      "Score: 0.012507826089859009\t \n",
      "Topic: 0.060*\"covid\" + 0.044*\"coronavirus\" + 0.019*\"open\" + 0.016*\"melbourne\" + 0.016*\"lockdown\" + 0.014*\"dy\" + 0.014*\"sydney\" + 0.014*\"final\" + 0.012*\"hospital\" + 0.012*\"crash\"\n",
      "\n",
      "Score: 0.012507826089859009\t \n",
      "Topic: 0.078*\"australia\" + 0.024*\"donald\" + 0.017*\"restriction\" + 0.014*\"coronavirus\" + 0.013*\"world\" + 0.011*\"australian\" + 0.010*\"climate\" + 0.010*\"win\" + 0.010*\"attack\" + 0.009*\"high\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test document has the highest probability to be part of the topic that our model assigned, which is the accurate classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing our LDA model\n",
    "\n",
    "Now that we have a trained model let’s visualize the topics for interpretability. \n",
    "To do so, we’ll use a popular visualization package, *pyLDAvis* which is designed to help interactively with:\n",
    "\n",
    "1. Better understanding and interpreting individual topics, and\n",
    "2. Better understanding the relationships between the topics.\n",
    "\n",
    "For (1), you can manually select each topic to view its top most frequent and/or “relevant” terms, using different values of the λ parameter. This can help when you’re trying to assign a human interpretable name or “meaning” to each topic.\n",
    "For (2), exploring the Intertopic Distance Plot can help you learn about how topics relate to each other, including potential higher-level structure between groups of topics.\n",
    "\n",
    "You need to install *pyldavis* through the command line, following the instructions:\n",
    "\n",
    "https://anaconda.org/conda-forge/pyldavis\n",
    "\n",
    "WARNING: running the next cell takes a long time and you need some memory to run it. However, the result is spectacular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el487222057126375207981773025\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el487222057126375207981773025_data = {\"mdsDat\": {\"x\": [0.2784245815201312, -0.15868903257625314, 0.28220298373150676, -0.07481536695080719, -0.14953217186390994, 0.04384450227481163, -0.2060052932808838, -0.009500383345480253, -0.1054822059838466, 0.09955238647473126], \"y\": [0.007178216243639324, 0.2530688097564755, -0.009979181169386942, -0.26940097060265195, -0.12592241257625778, -0.08374221481314305, -0.09917559879356962, -0.01841224799889841, 0.24105920563840258, 0.10532639431539063], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [12.05267850802528, 10.9658681160183, 10.85246162411542, 9.987234639256368, 9.761163494731798, 9.73996768848181, 9.672859808841778, 9.073688265229613, 8.991288430781651, 8.902789424517978]}, \"tinfo\": {\"Term\": [\"australia\", \"covid\", \"police\", \"trump\", \"queensland\", \"case\", \"coronavirus\", \"victoria\", \"election\", \"home\", \"court\", \"government\", \"health\", \"donald\", \"school\", \"coast\", \"news\", \"child\", \"record\", \"tasmania\", \"woman\", \"vaccine\", \"national\", \"border\", \"people\", \"murder\", \"open\", \"victorian\", \"minister\", \"live\", \"coast\", \"national\", \"live\", \"federal\", \"plan\", \"gold\", \"care\", \"aged\", \"industry\", \"rural\", \"fear\", \"local\", \"park\", \"farm\", \"week\", \"port\", \"green\", \"social\", \"tourism\", \"land\", \"housing\", \"extended\", \"prince\", \"closure\", \"territory\", \"tree\", \"impact\", \"data\", \"cattle\", \"project\", \"farmer\", \"government\", \"concern\", \"council\", \"regional\", \"funding\", \"future\", \"water\", \"beach\", \"case\", \"child\", \"vaccine\", \"murder\", \"court\", \"charged\", \"trial\", \"scott\", \"charge\", \"quarantine\", \"accused\", \"drug\", \"alleged\", \"abuse\", \"arrested\", \"face\", \"zealand\", \"look\", \"jailed\", \"investigation\", \"appeal\", \"protester\", \"shot\", \"kid\", \"coal\", \"rape\", \"prime\", \"allegation\", \"march\", \"hears\", \"woman\", \"sexual\", \"test\", \"police\", \"death\", \"life\", \"year\", \"shooting\", \"health\", \"election\", \"people\", \"minister\", \"morrison\", \"labor\", \"andrew\", \"country\", \"service\", \"rate\", \"show\", \"rule\", \"assault\", \"medium\", \"parliament\", \"aboriginal\", \"push\", \"sport\", \"law\", \"briefing\", \"told\", \"hour\", \"russia\", \"parent\", \"remote\", \"decision\", \"defends\", \"increase\", \"legal\", \"morning\", \"action\", \"refugee\", \"change\", \"indigenous\", \"campaign\", \"say\", \"need\", \"government\", \"call\", \"community\", \"trump\", \"queensland\", \"victoria\", \"news\", \"record\", \"market\", \"street\", \"price\", \"interview\", \"india\", \"warning\", \"wall\", \"travel\", \"video\", \"fall\", \"christmas\", \"michael\", \"mental\", \"close\", \"east\", \"share\", \"free\", \"company\", \"alan\", \"cyclone\", \"tuesday\", \"sale\", \"george\", \"thursday\", \"outback\", \"trade\", \"brisbane\", \"south\", \"coronavirus\", \"australian\", \"covid\", \"year\", \"australia\", \"donald\", \"restriction\", \"climate\", \"win\", \"violence\", \"baby\", \"near\", \"cricket\", \"hit\", \"take\", \"hong\", \"kill\", \"kong\", \"domestic\", \"johnson\", \"footage\", \"airport\", \"leaf\", \"best\", \"survivor\", \"politics\", \"whale\", \"response\", \"music\", \"aussie\", \"artist\", \"breach\", \"early\", \"lost\", \"shark\", \"security\", \"high\", \"world\", \"centre\", \"attack\", \"chinese\", \"killed\", \"island\", \"million\", \"coronavirus\", \"australian\", \"china\", \"border\", \"north\", \"protest\", \"amid\", \"president\", \"biden\", \"liberal\", \"john\", \"program\", \"season\", \"story\", \"talk\", \"crisis\", \"david\", \"hobart\", \"peter\", \"international\", \"jail\", \"sentenced\", \"korea\", \"monday\", \"meet\", \"chief\", \"warns\", \"thousand\", \"wednesday\", \"killing\", \"staff\", \"rollout\", \"strike\", \"west\", \"student\", \"china\", \"game\", \"worker\", \"say\", \"south\", \"australian\", \"lockdown\", \"dy\", \"final\", \"tasmanian\", \"update\", \"weather\", \"mark\", \"doctor\", \"friday\", \"outbreak\", \"latest\", \"lead\", \"grand\", \"race\", \"patient\", \"truck\", \"cut\", \"indonesia\", \"online\", \"injured\", \"smith\", \"mount\", \"global\", \"open\", \"point\", \"tourist\", \"wild\", \"king\", \"tiger\", \"beat\", \"covid\", \"super\", \"hospital\", \"coronavirus\", \"melbourne\", \"crash\", \"sydney\", \"australian\", \"storm\", \"home\", \"tasmania\", \"business\", \"royal\", \"return\", \"commission\", \"power\", \"fight\", \"town\", \"rain\", \"station\", \"number\", \"prison\", \"hill\", \"testing\", \"arrest\", \"release\", \"festival\", \"rugby\", \"james\", \"building\", \"womens\", \"save\", \"ship\", \"know\", \"animal\", \"england\", \"good\", \"film\", \"track\", \"perth\", \"resident\", \"adelaide\", \"world\", \"star\", \"sydney\", \"school\", \"missing\", \"guilty\", \"drum\", \"announces\", \"search\", \"northern\", \"emergency\", \"finance\", \"daniel\", \"white\", \"fatal\", \"teen\", \"bushfires\", \"facebook\", \"rescue\", \"great\", \"cancer\", \"continues\", \"money\", \"like\", \"human\", \"france\", \"united\", \"pleads\", \"boat\", \"drone\", \"flooding\", \"treatment\", \"mean\", \"police\", \"family\", \"dead\", \"help\", \"budget\", \"house\", \"crash\", \"officer\", \"woman\", \"victorian\", \"premier\", \"claim\", \"speaks\", \"hotel\", \"pandemic\", \"road\", \"black\", \"body\", \"question\", \"find\", \"history\", \"club\", \"expert\", \"result\", \"turnbull\", \"released\", \"economy\", \"loss\", \"kohler\", \"paul\", \"recovery\", \"coach\", \"day\", \"inside\", \"football\", \"female\", \"berejiklian\", \"grant\", \"cabinet\", \"reveals\", \"time\", \"bushfire\", \"long\", \"player\", \"say\", \"report\", \"state\", \"death\"], \"Freq\": [42906.0, 38754.0, 32779.0, 21670.0, 20587.0, 20874.0, 47081.0, 17699.0, 17826.0, 14536.0, 15121.0, 21650.0, 13989.0, 13189.0, 12204.0, 13607.0, 11526.0, 11894.0, 11360.0, 10726.0, 18447.0, 11301.0, 11557.0, 10274.0, 10727.0, 10773.0, 10183.0, 9535.0, 10232.0, 10641.0, 13606.65931344403, 11556.660246481615, 10640.748898100477, 9970.3633225052, 10392.934641477841, 8442.155620289539, 8011.05553125634, 6818.254057107862, 6535.604201463256, 6520.905870948702, 6265.080026457096, 6063.582939805718, 5892.733476236606, 5424.043903520243, 5259.482718661559, 5145.200609842544, 5031.105734869445, 4530.173420370017, 4266.813386955522, 4180.30061498036, 4056.6659703267587, 3895.14409912878, 3634.242101954529, 3461.070686104011, 3315.830265999723, 3293.754037883915, 3216.858076159918, 3101.946697433798, 3025.0485255294952, 3559.560109416991, 7802.734039300322, 15364.716295275603, 5591.896994074594, 6018.71880551559, 5606.539754341456, 4019.9564541454, 3862.3712298123346, 4360.682586208968, 4014.559509578351, 20873.885449027686, 11893.349460971804, 11300.519993912605, 10773.00520813437, 15120.065469081883, 8669.388939318891, 8281.98110254908, 7767.606585903836, 6496.105860383204, 6062.686110994104, 5873.409011448326, 5574.694974999298, 5444.276468052422, 4877.639060336272, 4430.292785930811, 8331.712577162465, 4031.6653621018813, 3851.0074885424256, 3803.3567049641997, 3781.8425377675726, 3590.4341878021005, 3572.9791348298013, 3247.2528853851795, 3123.51482438924, 3109.49723502687, 2992.4315764434186, 2914.8568189511425, 2911.3188111106033, 2731.3038460885887, 2672.8876481043703, 12782.459219560817, 3789.1676158713326, 6315.526698592854, 14271.584772274548, 8976.07067513989, 5183.718105312074, 6741.539498147556, 3656.177187505461, 13988.269555569863, 17824.756489422012, 10726.469008239368, 10231.742103459253, 8678.912433246005, 7570.932363911969, 7250.213680633185, 6845.325625529841, 6220.932514121992, 5452.437094071589, 5451.35221153804, 5289.497176238008, 5252.046553558655, 5049.812053896718, 4995.742486410986, 4567.03904216905, 3916.646561637619, 3841.7248467971476, 3923.7616966394876, 3640.4279631193936, 3512.5019467400484, 3393.696790277191, 3388.5629305311672, 3297.755476349208, 2950.3932038679573, 2918.714690747998, 2884.4405336208833, 2850.323309187301, 2772.392296229006, 2755.0970056293068, 4061.978744976225, 3292.105899382047, 9366.462993446563, 6639.750051566471, 3773.6092346435644, 10645.629338781926, 3919.020452925652, 6284.787062488146, 4825.154942751286, 4410.7448827485305, 21669.4475950613, 20586.936661654483, 17698.926398601827, 11525.822356975546, 11359.398056103122, 9346.45885444956, 5592.144304834528, 5584.901799730376, 5343.356588680789, 4524.752578311554, 4332.350283912602, 4238.581793763136, 4228.592149594121, 4123.393991141067, 4155.368858430049, 3950.970461815562, 3940.4232792325247, 3823.1214876919685, 3643.344259538259, 3425.2776687307564, 3375.20805050224, 3274.2069972757154, 3200.4580868372327, 3187.7665659898494, 3037.3300912103546, 2950.520235128337, 2900.355644377864, 2868.8797098695195, 2831.6324286343324, 2814.0044297035333, 3731.063811099184, 6945.440997497357, 8009.85116242193, 10287.586836905512, 6221.171649557242, 4922.183018251578, 3355.9621174783815, 42905.91314991194, 13188.462164191296, 9328.117006886341, 5708.110591903422, 5678.867598512775, 4528.0105653218025, 4429.806681501258, 4168.3097282477565, 3896.328154366385, 3802.631158955338, 3521.0417939698496, 3377.4394158892314, 3316.387635161788, 3171.055379061864, 3153.059022041517, 3132.978884388602, 3045.004422635209, 2896.811027561449, 2697.3764208790417, 2481.4278079342935, 2393.9468664436135, 2358.9411929283465, 2320.751418733643, 2305.913591394664, 2247.1064328776356, 2238.5030705776326, 2172.660307652155, 2161.3794061444446, 2089.2555111085167, 2076.5252454303077, 3511.375700990138, 3255.069148924494, 4898.138488278066, 6982.530267699045, 3631.436906829328, 5316.18441593405, 3574.8940601912277, 3883.8390231999583, 4153.601801578963, 3740.829125144577, 7659.6804703193, 6238.781934870381, 3976.2405918488766, 10273.206763838742, 9152.755022488107, 7430.052917581762, 6188.3980909069705, 5784.298842547014, 5201.890841035095, 4949.11926499539, 4874.169096590279, 4789.885368486046, 4777.986483220632, 4338.261001767465, 4202.100491535647, 4103.716148077325, 4027.0916543921253, 4024.2418313117673, 3916.522907535438, 3812.811698963978, 3793.349772609398, 3761.3538808884978, 3673.885311555056, 3564.045796891373, 3549.2042122271073, 3529.2462650946404, 3418.886489954563, 3279.716940096399, 3256.78006159468, 2952.431255070003, 2809.437446251466, 2787.8255862166016, 2690.5789776598203, 6862.214250646657, 5020.435519862095, 7791.51326049283, 3663.9661717709287, 4306.093646073962, 6145.422891535627, 4596.491357911134, 3813.6090574675254, 8859.39796196336, 7758.559504215976, 7559.1231104061635, 6007.696128832851, 4899.609511359636, 4346.667464760088, 4285.911547237226, 4075.0897854844206, 3655.191911970114, 3500.5058853782243, 3515.9907054273745, 3468.537862210431, 3118.5295909245388, 3070.289697501035, 3026.9406141344566, 2954.2486976000714, 2911.7690183734503, 2872.147907524228, 2835.7426544249893, 2747.542858740103, 2706.658058457489, 2573.387348706226, 2490.6530668350183, 10180.151322694197, 2459.172832349655, 2263.0622704655016, 2185.9280560653087, 2107.964600904985, 2104.3574986221847, 4581.728396380532, 32520.46652965183, 3012.168345656731, 6580.368657494076, 23713.807519842645, 8924.610114171526, 6438.815676010229, 7658.507330436554, 6233.247081621297, 3185.818582634626, 14535.439561401725, 10725.574395925674, 9198.566938501006, 7633.838801611575, 7097.619459379916, 6253.7059575835865, 6204.8794391500605, 6189.060951677497, 4870.558121443107, 4613.912028426384, 4319.8442830717895, 4103.563524379778, 4074.50132037146, 3980.3453320662948, 3884.074760835182, 3817.154961920852, 3350.9291227194653, 3270.421892463747, 3261.5989283174677, 3200.1937791200858, 3134.073129013875, 3108.672937658114, 3104.072959152839, 3058.7021294083215, 2693.0694435545433, 2596.3643559578027, 2588.263763384359, 2559.667927597794, 2522.391747916249, 2453.8990853304945, 4785.516042596874, 3929.7631583392613, 4387.751014125119, 3833.3026644735005, 2671.340772868092, 2777.9128048506313, 12203.497882698044, 7000.95244185206, 6426.338285187975, 5801.574920149798, 5178.818842480764, 5159.706037237669, 4880.635149639819, 4721.888444118065, 4641.967692173206, 4571.774346209435, 4147.042514305514, 3841.209129856071, 3791.7592451382775, 3656.5565930731436, 3605.50078424331, 3579.5655102549445, 3431.528891177086, 3431.6749271039657, 3052.924391112629, 3027.900663958173, 2983.145127664107, 2814.5560717543017, 2789.0209833139497, 2768.860016982767, 2653.509064842375, 2416.6571637054203, 2385.47024935301, 2269.452713868958, 2234.383834821543, 2212.2643382774513, 18491.894400024623, 7497.199009316195, 4714.555556254169, 5114.929066638206, 3872.7177943312513, 4670.727348095787, 4712.3739679400405, 2883.2541982602797, 3039.7731492716675, 9535.046412099087, 7222.240008262986, 6364.34344978398, 6065.6094134926225, 6035.884619838352, 5969.196243452815, 5721.245677950797, 4739.606826935612, 4262.30713092104, 4186.061724482112, 3861.91379656945, 3707.5406373213254, 3683.9169688121738, 3292.68511756267, 3270.5470823552923, 3268.778549022898, 3156.957006086967, 3131.1795191254005, 3072.5116967819367, 3020.0947290309614, 2687.935576013756, 2730.851020889649, 2637.112923686788, 2583.860316356494, 2457.9140623286726, 2365.964788897335, 2329.170059935376, 2259.280458636157, 2228.9170992079057, 2222.4647395647535, 2613.8516844007063, 6318.049530181321, 4509.098575934861, 2807.0833668160335, 2836.1035924632934, 5242.26770607444, 3354.054366991604, 3064.628744568442, 2816.5638995816716], \"Total\": [42906.0, 38754.0, 32779.0, 21670.0, 20587.0, 20874.0, 47081.0, 17699.0, 17826.0, 14536.0, 15121.0, 21650.0, 13989.0, 13189.0, 12204.0, 13607.0, 11526.0, 11894.0, 11360.0, 10726.0, 18447.0, 11301.0, 11557.0, 10274.0, 10727.0, 10773.0, 10183.0, 9535.0, 10232.0, 10641.0, 13607.474398871636, 11557.475327122987, 10641.56402924043, 9971.178433697412, 10393.794467806862, 8442.970689816984, 8011.87062882011, 6819.069169539322, 6536.41927143402, 6521.720901383269, 6265.8951378308975, 6064.39805387391, 5893.5485570811325, 5424.858972758898, 5260.29781407702, 5146.018351789732, 5031.920801502523, 4530.98854692395, 4267.628479386192, 4181.115688638982, 4057.4810420066246, 3895.959181067865, 3635.0572296016626, 3461.8858285041583, 3316.6453835438115, 3294.5691281260406, 3217.6731753073627, 3102.761809949388, 3025.863572992714, 3560.527259068092, 9288.547556479834, 21650.223099311235, 6876.801317516837, 7879.220196926931, 7159.31898696626, 5277.656721433189, 4851.311395687579, 8718.38531490509, 5910.455943166663, 20874.71953196224, 11894.183406352578, 11301.354310492441, 10773.839118493068, 15121.401333642314, 8670.222849177328, 8282.815044332965, 7768.440655651844, 6496.939784680244, 6063.5207375918335, 5874.246233454408, 5575.528899991037, 5445.1103908126115, 4878.472993099773, 4431.126708997183, 8333.302687243537, 4032.499363215442, 3851.8414851147104, 3804.190621684308, 3782.676521819044, 3591.2681200175357, 3573.8131374421446, 3248.086829776245, 3124.3488116744848, 3110.3312138041183, 2993.2655012660707, 2915.6908413380975, 2912.152774637107, 2732.1424875824146, 2673.721587497025, 18447.635213519246, 4190.125469764267, 8912.410162208016, 32779.595701931605, 17074.33544268418, 9481.534376864318, 18742.5773991444, 4957.0218465469725, 13989.094139120793, 17826.10548252035, 10727.293596846914, 10232.566672492057, 8679.737071866859, 7571.757177972998, 7251.038307817723, 6846.150333244805, 6221.757082765308, 5453.261636994572, 5452.176811549185, 5290.3217684945885, 5252.871138049701, 5050.636688880975, 4996.567049238425, 4567.863605685769, 3917.4711114385495, 3842.5494922341986, 3924.621013413378, 3641.252656889673, 3513.326543876051, 3394.52134396603, 3389.3875246085304, 3298.5800522185436, 2951.2178046688896, 2919.5398046485766, 2885.265076316829, 2851.1479353490304, 2773.216840790667, 2755.9215935503953, 4065.820204642306, 3298.4730782597826, 12348.034659361696, 9098.88608379201, 4459.374643173634, 31473.957354438146, 4985.635340091328, 21650.223099311235, 10626.761466793778, 8767.920897170388, 21670.29017037333, 20587.7791882079, 17699.76899768474, 11526.664844913497, 11360.2405342288, 9347.301467415802, 5592.98676722104, 5585.7442438120015, 5344.199006423335, 4525.595096062513, 4333.19276210741, 4239.424213972204, 4229.434694552092, 4124.23650389287, 4156.234858802471, 3951.8129711542847, 3941.2657448935197, 3823.9640268940193, 3644.1867368074704, 3426.120128951234, 3376.0504715521656, 3275.049478261936, 3201.300563623165, 3188.6090990451266, 3038.1725440870396, 2951.3626579147654, 2901.198314483611, 2869.722235357993, 2832.474854315148, 2814.846909219968, 3733.1181869039983, 9242.03344246524, 12607.09551245567, 47081.334986430586, 29364.441775531435, 38754.06177585416, 18742.5773991444, 42906.75632245135, 13189.296896226651, 9328.95198324875, 5708.94525688025, 5679.70271451071, 4528.845154294661, 4430.641313707721, 4169.144360215419, 3897.1627579383676, 3803.4657797892023, 3521.9056320899986, 3378.274022636938, 3317.222261236906, 3171.889987441431, 3153.8936040329127, 3133.81350519024, 3045.839087375978, 2897.6456397404713, 2698.2110507254633, 2482.262420864468, 2394.781505334569, 2359.775818897408, 2321.5860419095534, 2306.7482546654264, 2247.9410574722897, 2239.3380466099657, 2173.4949254381577, 2162.214079459153, 2090.0902664411246, 2077.3598889548525, 3518.8209482886946, 3278.9209364053486, 7160.045158377818, 12577.638764203328, 4825.846914267314, 9386.329677710022, 4877.8313912626645, 5896.367814406496, 7759.855604432014, 6739.290934522744, 47081.334986430586, 29364.441775531435, 14881.861551050903, 10274.038110915299, 9153.586181087252, 7430.88412844272, 6189.229338485085, 5785.130014954818, 5202.722382259631, 4949.9504513967195, 4875.000265064715, 4790.718215668112, 4778.8188982898455, 4339.092168511449, 4202.931643746041, 4104.547333307012, 4027.9228300730647, 4025.073000898227, 3917.3540734623734, 3813.642881910495, 3794.180922599799, 3762.1850586987825, 3674.7164280436373, 3564.8769567919544, 3550.0353764467004, 3530.077597220252, 3419.7176672421497, 3280.54811453861, 3257.6112164683686, 2953.2624410721037, 2810.2686282319423, 2788.6571697737018, 2691.4101238621797, 6877.17476292219, 7091.159584522168, 14881.861551050903, 5365.8770525972595, 8737.768375738511, 31473.957354438146, 12607.09551245567, 29364.441775531435, 8860.231963070755, 7759.3931703067565, 7559.957641335799, 6008.529815283892, 4900.44325143166, 4347.501183228831, 4286.745247839992, 4075.9234711224976, 3656.0255765713723, 3501.3396071337056, 3516.8343804201836, 3469.371532976372, 3119.363237849147, 3071.1233669405565, 3027.774301664135, 2955.082366412902, 2912.6027023879715, 2872.981591444888, 2836.5763619883783, 2748.3765213848287, 2707.4917541290433, 2574.2210451392593, 2491.487742777097, 10183.819938899376, 2460.0645408893915, 2263.8959560947173, 2186.7617278970474, 2108.7983055314166, 2105.195193718372, 4583.644746779871, 38754.06177585416, 3170.512860670339, 8365.201281398968, 47081.334986430586, 16202.509833423903, 11151.925394826512, 21552.46545151419, 29364.441775531435, 5513.1369479180485, 14536.263707364218, 10726.39853558353, 9199.392685483857, 7634.6629132699145, 7098.443594412364, 6254.530062731327, 6205.703582576224, 6189.885078955263, 4871.382255705356, 4614.73614950013, 4320.67026055264, 4104.387679609731, 4075.3254641482545, 3981.1694386655977, 3884.8989684048174, 3817.9791209691175, 3351.7532653448006, 3271.2461475764117, 3262.4230436080093, 3201.017901449201, 3134.897249114323, 3109.497064479061, 3104.897086138179, 3059.5262647820305, 2693.8935872027805, 2597.1884736578063, 2589.0957951957866, 2560.4921920047095, 2523.215873870059, 2454.72321084889, 9089.019877337521, 6346.14287052003, 10739.966962010698, 12577.638764203328, 3871.40846534691, 21552.46545151419, 12204.320784262864, 7001.775312649842, 6427.161156094354, 5802.39778423922, 5179.641789124825, 5160.528899992209, 4881.458116648423, 4722.711342801595, 4642.790624278723, 4572.597348567138, 4147.865407290172, 3842.0319942548017, 3792.5821371580596, 3657.379574401563, 3606.3237103936394, 3580.38841047854, 3432.3517678383787, 3432.4982482467935, 3053.7472832150847, 3028.7235624047507, 2983.9680446231823, 2815.378955764448, 2789.8439568329463, 2769.6829285211606, 2654.331914048932, 2417.4800297179904, 2386.293146242756, 2270.2756208780975, 2235.2067345734117, 2213.087261254864, 32779.595701931605, 12158.984877650584, 7265.342436171832, 9082.818990922176, 6163.432912131493, 9091.528359786596, 11151.925394826512, 5159.893357360717, 18447.635213519246, 9535.871243301513, 7223.064822476845, 6365.1682356692645, 6066.4341968156605, 6036.709509952724, 5970.023485305427, 5722.070445370299, 4740.431631486962, 4263.13190642919, 4186.886505131285, 3862.738577691852, 3708.3654249609735, 3684.741743899693, 3293.5099034949876, 3271.3718794997744, 3269.6033018029807, 3157.7818000483303, 3132.0043279514616, 3073.3364776795092, 3020.919637148182, 2688.7603721791384, 2731.6969794399274, 2637.937695501668, 2584.6851190834764, 2458.73886832995, 2366.789578133002, 2329.994850669495, 2260.105323732745, 2229.742640872205, 2223.289590271264, 2677.4020534863466, 8069.744300909454, 8493.637785269555, 3761.6913152391026, 4169.922867824062, 31473.957354438146, 9905.168392801279, 11389.971246798348, 17074.33544268418], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.9087, -4.072, -4.1545, -4.2196, -4.1781, -4.386, -4.4384, -4.5996, -4.642, -4.6442, -4.6842, -4.7169, -4.7455, -4.8284, -4.8592, -4.8812, -4.9036, -5.0085, -5.0683, -5.0888, -5.1189, -5.1595, -5.2288, -5.2776, -5.3205, -5.3272, -5.3508, -5.3872, -5.4123, -5.2496, -4.4647, -3.7871, -4.7979, -4.7243, -4.7953, -5.1279, -5.1679, -5.0466, -5.1293, -3.3862, -3.9487, -3.9999, -4.0477, -3.7087, -4.2649, -4.3106, -4.3748, -4.5535, -4.6226, -4.6543, -4.7065, -4.7302, -4.8401, -4.9363, -4.3046, -5.0305, -5.0764, -5.0888, -5.0945, -5.1464, -5.1513, -5.2469, -5.2858, -5.2903, -5.3286, -5.3549, -5.3561, -5.4199, -5.4416, -3.8766, -5.0926, -4.5817, -3.7664, -4.2302, -4.7792, -4.5164, -5.1283, -3.7761, -3.5337, -4.0416, -4.0888, -4.2534, -4.39, -4.4333, -4.4908, -4.5864, -4.7183, -4.7185, -4.7486, -4.7557, -4.795, -4.8057, -4.8955, -5.0491, -5.0684, -5.0473, -5.1222, -5.158, -5.1924, -5.1939, -5.2211, -5.3324, -5.3432, -5.355, -5.3669, -5.3946, -5.4009, -5.0127, -5.2228, -4.1772, -4.5212, -5.0863, -4.0492, -5.0485, -4.5762, -4.8405, -4.9303, -3.2553, -3.3066, -3.4577, -3.8866, -3.9012, -4.0962, -4.6099, -4.6112, -4.6554, -4.8217, -4.8651, -4.887, -4.8894, -4.9146, -4.9068, -4.9573, -4.9599, -4.9902, -5.0383, -5.1001, -5.1148, -5.1452, -5.1679, -5.1719, -5.2203, -5.2493, -5.2664, -5.2773, -5.2904, -5.2966, -5.0145, -4.3932, -4.2506, -4.0003, -4.5033, -4.7375, -5.1205, -2.5493, -3.729, -4.0753, -4.5665, -4.5716, -4.7981, -4.82, -4.8808, -4.9483, -4.9726, -5.0496, -5.0912, -5.1095, -5.1543, -5.16, -5.1664, -5.1948, -5.2447, -5.3161, -5.3995, -5.4354, -5.4501, -5.4664, -5.4729, -5.4987, -5.5025, -5.5324, -5.5376, -5.5715, -5.5776, -5.0523, -5.1281, -4.7195, -4.3649, -5.0187, -4.6376, -5.0344, -4.9515, -4.8844, -4.989, -4.2724, -4.4776, -4.928, -3.9766, -4.0921, -4.3006, -4.4835, -4.551, -4.6571, -4.707, -4.7222, -4.7397, -4.7421, -4.8387, -4.8706, -4.8943, -4.9131, -4.9138, -4.941, -4.9678, -4.9729, -4.9814, -5.0049, -5.0353, -5.0394, -5.0451, -5.0769, -5.1184, -5.1254, -5.2235, -5.2732, -5.2809, -5.3164, -4.3801, -4.6927, -4.2531, -5.0076, -4.8461, -4.4905, -4.7809, -4.9676, -4.1178, -4.2505, -4.2765, -4.5062, -4.7101, -4.8298, -4.8439, -4.8944, -5.0031, -5.0463, -5.0419, -5.0555, -5.1619, -5.1775, -5.1917, -5.216, -5.2305, -5.2442, -5.2569, -5.2885, -5.3035, -5.354, -5.3867, -3.9788, -5.3994, -5.4825, -5.5172, -5.5535, -5.5552, -4.7772, -2.8174, -5.1966, -4.4152, -3.1332, -4.1104, -4.4369, -4.2634, -4.4694, -5.1405, -3.5587, -3.8627, -4.0163, -4.2027, -4.2755, -4.4021, -4.41, -4.4125, -4.6521, -4.7062, -4.7721, -4.8235, -4.8306, -4.8539, -4.8784, -4.8958, -5.0261, -5.0504, -5.0531, -5.0721, -5.093, -5.1011, -5.1026, -5.1173, -5.2446, -5.2812, -5.2843, -5.2954, -5.3101, -5.3376, -4.6697, -4.8667, -4.7565, -4.8916, -5.2527, -5.2136, -3.7245, -4.2801, -4.3658, -4.4681, -4.5816, -4.5853, -4.6409, -4.674, -4.691, -4.7063, -4.8038, -4.8804, -4.8934, -4.9297, -4.9437, -4.9509, -4.9932, -4.9931, -5.1101, -5.1183, -5.1332, -5.1914, -5.2005, -5.2077, -5.2503, -5.3438, -5.3568, -5.4066, -5.4222, -5.4322, -3.3089, -4.2117, -4.6755, -4.594, -4.8722, -4.6849, -4.676, -5.1673, -5.1144, -3.9613, -4.2391, -4.3656, -4.4137, -4.4186, -4.4297, -4.4721, -4.6603, -4.7665, -4.7845, -4.8651, -4.9059, -4.9123, -5.0246, -5.0313, -5.0319, -5.0667, -5.0749, -5.0938, -5.111, -5.2275, -5.2117, -5.2466, -5.267, -5.317, -5.3551, -5.3708, -5.4012, -5.4148, -5.4177, -5.2555, -4.3729, -4.7102, -5.1841, -5.1739, -4.5595, -5.0061, -5.0964, -5.1808], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.1158, 2.1158, 2.1158, 2.1158, 2.1158, 2.1158, 2.1158, 2.1158, 2.1158, 2.1158, 2.1158, 2.1157, 2.1157, 2.1157, 2.1157, 2.1157, 2.1157, 2.1157, 2.1157, 2.1157, 2.1157, 2.1157, 2.1157, 2.1156, 2.1156, 2.1156, 2.1156, 2.1156, 2.1156, 2.1156, 1.9416, 1.7729, 1.909, 1.8465, 1.8714, 1.8437, 1.8879, 1.4231, 1.7291, 2.2103, 2.2103, 2.2103, 2.2103, 2.2103, 2.2103, 2.2103, 2.2103, 2.2103, 2.2102, 2.2102, 2.2102, 2.2102, 2.2102, 2.2102, 2.2102, 2.2102, 2.2102, 2.2102, 2.2102, 2.2102, 2.2101, 2.2101, 2.2101, 2.2101, 2.2101, 2.2101, 2.2101, 2.2101, 2.2101, 1.8435, 2.1098, 1.8659, 1.3788, 1.5674, 1.6066, 1.1879, 1.906, 2.2207, 2.2207, 2.2207, 2.2207, 2.2207, 2.2207, 2.2207, 2.2207, 2.2206, 2.2206, 2.2206, 2.2206, 2.2206, 2.2206, 2.2206, 2.2206, 2.2206, 2.2206, 2.2206, 2.2206, 2.2205, 2.2205, 2.2205, 2.2205, 2.2205, 2.2205, 2.2205, 2.2205, 2.2205, 2.2205, 2.2198, 2.2188, 1.9444, 1.9057, 2.0538, 1.1368, 1.9801, 0.9839, 1.4312, 1.5337, 2.3038, 2.3038, 2.3038, 2.3038, 2.3038, 2.3038, 2.3037, 2.3037, 2.3037, 2.3037, 2.3037, 2.3037, 2.3037, 2.3037, 2.3037, 2.3036, 2.3036, 2.3036, 2.3036, 2.3036, 2.3036, 2.3036, 2.3036, 2.3036, 2.3036, 2.3036, 2.3036, 2.3036, 2.3036, 2.3036, 2.3033, 2.0182, 1.8503, 0.7829, 0.752, 0.2404, 0.5838, 2.3267, 2.3267, 2.3267, 2.3266, 2.3266, 2.3266, 2.3266, 2.3266, 2.3265, 2.3265, 2.3265, 2.3265, 2.3265, 2.3265, 2.3265, 2.3265, 2.3265, 2.3265, 2.3264, 2.3264, 2.3264, 2.3264, 2.3264, 2.3264, 2.3264, 2.3264, 2.3264, 2.3264, 2.3264, 2.3264, 2.3246, 2.3195, 1.9471, 1.7382, 2.0424, 1.7583, 2.016, 1.9092, 1.7018, 1.7381, 0.5109, 0.7778, 1.007, 2.3289, 2.3288, 2.3288, 2.3288, 2.3288, 2.3288, 2.3288, 2.3288, 2.3288, 2.3288, 2.3287, 2.3287, 2.3287, 2.3287, 2.3287, 2.3287, 2.3287, 2.3287, 2.3287, 2.3287, 2.3287, 2.3287, 2.3287, 2.3287, 2.3287, 2.3287, 2.3287, 2.3286, 2.3286, 2.3286, 2.3268, 1.9836, 1.6818, 1.9474, 1.6213, 0.6955, 1.32, 0.2877, 2.3358, 2.3357, 2.3357, 2.3357, 2.3357, 2.3357, 2.3357, 2.3356, 2.3356, 2.3356, 2.3356, 2.3356, 2.3356, 2.3356, 2.3356, 2.3356, 2.3356, 2.3356, 2.3356, 2.3355, 2.3355, 2.3355, 2.3355, 2.3355, 2.3355, 2.3355, 2.3355, 2.3355, 2.3354, 2.3354, 2.1605, 2.2846, 2.0959, 1.65, 1.7395, 1.7866, 1.3012, 0.786, 1.7874, 2.3997, 2.3997, 2.3997, 2.3997, 2.3997, 2.3997, 2.3997, 2.3997, 2.3996, 2.3996, 2.3996, 2.3996, 2.3996, 2.3996, 2.3996, 2.3996, 2.3995, 2.3995, 2.3995, 2.3995, 2.3995, 2.3995, 2.3995, 2.3995, 2.3995, 2.3995, 2.3995, 2.3995, 2.3995, 2.3995, 1.7583, 1.9205, 1.5046, 1.2116, 2.0288, 0.351, 2.4088, 2.4088, 2.4088, 2.4088, 2.4088, 2.4088, 2.4087, 2.4087, 2.4087, 2.4087, 2.4087, 2.4087, 2.4087, 2.4087, 2.4087, 2.4087, 2.4087, 2.4087, 2.4086, 2.4086, 2.4086, 2.4086, 2.4086, 2.4086, 2.4086, 2.4086, 2.4086, 2.4086, 2.4085, 2.4085, 1.8364, 1.9254, 1.9765, 1.8347, 1.9442, 1.7429, 1.5475, 1.8269, 0.6058, 2.4187, 2.4187, 2.4187, 2.4187, 2.4187, 2.4187, 2.4187, 2.4186, 2.4186, 2.4186, 2.4186, 2.4186, 2.4186, 2.4186, 2.4186, 2.4186, 2.4185, 2.4185, 2.4185, 2.4185, 2.4185, 2.4185, 2.4185, 2.4185, 2.4185, 2.4185, 2.4185, 2.4184, 2.4184, 2.4184, 2.3948, 2.1741, 1.7856, 2.1261, 2.0333, 0.6264, 1.3359, 1.106, 0.6167]}, \"token.table\": {\"Topic\": [3, 2, 2, 3, 6, 2, 4, 6, 7, 8, 9, 10, 1, 5, 4, 2, 2, 6, 3, 8, 9, 2, 8, 2, 5, 3, 2, 5, 9, 5, 5, 2, 3, 4, 5, 6, 7, 9, 5, 1, 9, 7, 8, 10, 5, 6, 10, 9, 10, 6, 5, 3, 4, 9, 3, 9, 8, 6, 9, 10, 9, 8, 10, 1, 3, 6, 9, 10, 1, 3, 4, 6, 9, 9, 1, 2, 1, 1, 5, 1, 3, 2, 2, 6, 2, 4, 5, 6, 5, 6, 4, 10, 5, 4, 1, 10, 10, 2, 1, 8, 1, 3, 6, 9, 4, 1, 10, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 3, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 9, 5, 6, 7, 4, 9, 1, 6, 10, 5, 7, 9, 2, 5, 9, 10, 3, 3, 7, 5, 5, 9, 2, 9, 7, 5, 4, 10, 3, 9, 8, 10, 1, 2, 3, 9, 4, 3, 5, 6, 9, 10, 1, 1, 9, 9, 1, 1, 10, 8, 8, 8, 7, 9, 10, 9, 5, 10, 9, 4, 7, 1, 3, 1, 3, 6, 8, 4, 7, 1, 8, 1, 3, 7, 10, 9, 1, 9, 3, 2, 1, 8, 9, 3, 5, 8, 10, 5, 6, 8, 5, 6, 7, 10, 10, 3, 2, 3, 4, 9, 10, 1, 9, 1, 3, 4, 1, 3, 7, 1, 7, 10, 6, 4, 2, 4, 5, 8, 6, 2, 8, 6, 5, 2, 5, 5, 7, 6, 7, 8, 10, 5, 6, 3, 1, 7, 3, 7, 5, 3, 6, 2, 6, 10, 9, 1, 1, 7, 6, 10, 2, 10, 5, 2, 7, 4, 9, 3, 6, 5, 7, 8, 9, 4, 4, 1, 5, 8, 3, 9, 6, 9, 3, 3, 7, 2, 5, 1, 5, 1, 3, 4, 6, 9, 8, 2, 9, 7, 5, 7, 4, 7, 10, 3, 1, 3, 7, 10, 3, 2, 7, 8, 6, 1, 7, 10, 9, 7, 2, 9, 10, 5, 1, 8, 10, 6, 4, 2, 1, 8, 6, 1, 6, 2, 3, 2, 4, 10, 7, 8, 2, 3, 4, 10, 3, 9, 1, 3, 8, 10, 3, 1, 2, 3, 4, 5, 6, 8, 9, 10, 9, 1, 8, 5, 5, 10, 8, 9, 10, 10, 6, 8, 8, 3, 1, 3, 4, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 2, 9, 6, 5, 6, 6, 3, 2, 3, 4, 5, 7, 8, 2, 9, 2, 3, 7, 1, 4, 6, 10, 3, 6, 4, 8, 1, 3, 4, 6, 9, 10, 8, 7, 8, 9, 6, 4, 6, 6, 9, 3, 7, 5, 2, 4, 5, 6, 7, 8, 9, 10, 5, 6, 8, 7, 9, 1, 2, 8, 8, 6, 4, 7, 6, 10, 3, 1, 7, 8, 8, 1, 4, 4, 9, 1, 2, 7, 4, 4, 10, 9, 7, 2, 4, 10, 4, 5, 4, 4, 6, 1, 3, 5, 8, 10, 7, 6, 1, 4, 6, 5, 9, 7, 5, 2, 7, 9, 8, 3, 5, 6, 8, 4, 5, 8, 2, 4, 5, 6, 7, 2], \"Freq\": [0.9998109388194749, 0.9999030448461144, 0.9997878479374408, 0.9990604098435183, 0.0007378585006229825, 0.14990735126978283, 0.015176955439114658, 9.311015606818808e-05, 0.1640600949921474, 0.40856736482720935, 0.08789598732836956, 0.1743022121596481, 0.9998432088731263, 0.9997771847145087, 0.9998089765705965, 0.999604150356689, 0.9997960756104256, 0.9998013745463525, 0.9998568056361523, 0.999542399918273, 0.9998760939171175, 0.9996468879584715, 0.9997435499414494, 0.9997457285536666, 0.9997722905021009, 0.9998341596382614, 0.2736959054507403, 0.566355559897289, 0.15980687356018314, 0.9998490417244161, 0.9999823728821245, 0.08673755896569924, 0.07730438117476925, 0.2118548701710306, 0.2124678564534737, 0.12988498229099996, 0.21226352769265935, 0.0695058334703542, 0.9998552548802051, 0.6793046151781095, 0.3206182430292696, 0.999641170537698, 0.00021816699487946266, 0.9995109414941249, 0.9994914232863308, 0.9998611530259439, 0.9999089467963012, 0.9998014338434694, 0.9997344894659527, 0.999898957848502, 0.9994385017326978, 0.9996559818810423, 0.7514580036130529, 0.24843017657243624, 0.371546187432752, 0.62838357376727, 0.9997137867550279, 0.21321841662953914, 0.2557208177357035, 0.5308679406861359, 0.9998962168421841, 0.999957313977424, 0.9994199629787739, 0.187168970171691, 0.4540423735939714, 0.15413915190609848, 0.08440953556762536, 0.12016831317709875, 0.14149966093697208, 0.8463070053504479, 0.007624387435589621, 0.002690960271384572, 0.0017939735142563813, 0.9998548438452814, 0.9998913326412213, 0.9999655309398942, 0.9997146027995373, 0.24741771158757933, 0.7524067929434678, 0.24141493624169144, 0.7585012723380349, 0.9998553496397704, 0.9998589598908125, 0.9996947383759778, 0.999900505456142, 0.2091808198403896, 0.2671708768664918, 0.5235904105995233, 0.7329076618768865, 0.26692189531851923, 0.9997942789397629, 0.999816464290336, 0.9998344253031485, 0.9996743479702936, 0.999744119665396, 0.9997986985381211, 0.9996445346289767, 0.9995720025577308, 0.9999651368903787, 0.9999152513896311, 0.29756199110349923, 0.5030839182665907, 0.09500541916029699, 0.10424364119149034, 0.9995937389828548, 0.813168759980873, 0.18671471527457814, 0.9997552897650726, 0.015951119487509165, 0.04337175232156287, 0.0018691058786961473, 0.21851546909120412, 0.16269717080468737, 0.041778764356765016, 0.5036815546295504, 0.0032284556086569815, 0.0002973577534289325, 0.008665854528500319, 0.7639080834861732, 0.23606396997579035, 0.9998319737094847, 0.9999073277924847, 6.613143702331247e-05, 0.0016256360524060562, 0.013753397078292508, 0.0005934861778625285, 0.1270060420625811, 0.013985630800064801, 0.00020642997490870555, 0.8391378480038881, 0.00025803746863588197, 2.5803746863588193e-05, 0.0033802908391300534, 0.5773890850262606, 0.42252793425124086, 0.9997016398825019, 0.9998666519685202, 0.9997930708546424, 0.9996140627070962, 0.9998693634007977, 0.9997544735960894, 0.9997708918189359, 0.9997349313158427, 0.18829119370742425, 0.16282783783324772, 0.6489714753877963, 0.5257012801541238, 0.15450088870839776, 0.15479372587425902, 0.16498445924623067, 0.9998151062548566, 0.9995615389631916, 0.9997734326640232, 0.9997166663987112, 0.9999016705562961, 0.9994580941386887, 0.9999051390459051, 0.9999314448519369, 0.9999493297609585, 0.9994783639450266, 0.9996730619741646, 0.9996793337919432, 0.9999379851913569, 0.9998493783020047, 0.9995767652947334, 0.9998451793041683, 0.9997538010478842, 0.9998436769558928, 0.00012000044130531598, 0.9999102381206916, 0.999702890032825, 0.0007401933706277479, 0.17452114805245345, 0.16374722232442732, 0.6165810777329139, 0.04432935852981734, 0.9998416598913978, 0.8400667545225095, 0.15987429584338414, 0.9997313936332792, 0.9998571412685328, 0.9998818160054753, 0.9995730245201147, 0.9996190602846151, 0.9998570120537015, 0.9995181253087972, 0.9998733271558874, 0.9998297092540446, 0.9998087942849363, 0.9994381206993695, 0.9997245135570504, 0.9996663927624588, 0.9996974895922479, 0.999679553463573, 0.9997194832065879, 0.7617016816713947, 0.23817388404501075, 0.7960734088174599, 0.20365627341057754, 0.6828333866178511, 0.3170031633834511, 0.9997483256919103, 0.9998042363328854, 0.9998850298250881, 0.9998077744559244, 0.7096924558014744, 0.2902972394866428, 0.9998835538469071, 0.9996669387495256, 0.9998975140480428, 0.9998170079500758, 0.99981933608538, 0.9999217862779454, 0.9997301186853562, 0.25928073677937485, 0.1775880375478266, 0.5631511544061581, 0.3157801312683694, 0.6840738978117972, 0.9997062574995578, 0.9999014592902539, 0.9998775380623437, 0.9997334207608192, 0.9999130651871995, 0.9996228776504212, 0.21194947262565922, 0.7865919514251764, 0.0013149713473673162, 0.9998824674350233, 0.9998464160589366, 0.13969048434336187, 0.06731541450247044, 0.1565193379689795, 0.5137750018644436, 0.12275163821038729, 0.9998814431905795, 0.999865397955159, 0.9997907881656445, 0.9995973778369063, 0.9998685043513877, 0.27014295787024684, 0.7297596583638889, 0.9996583370224817, 0.9999358560984831, 0.9998630022553682, 0.9996994929638657, 0.9998314257704768, 0.9997756433804403, 0.9998211526110833, 0.23209194755780832, 0.5353192393976323, 0.2324785526897758, 0.9996887542729539, 0.9996870236529365, 0.9996820069488708, 0.9997948174337788, 0.9997404104651114, 0.999888356999967, 0.9996315407468506, 0.6587106032480349, 0.3412270169245742, 0.9995725266218991, 0.9996214405477647, 0.9996682915735702, 0.999695577089548, 0.9997194141521444, 0.9998050385498675, 0.9998999997021563, 0.9997331600649049, 0.9997627467404127, 0.9998417647433331, 0.9998929105825536, 0.9995511653081631, 0.9995612168609506, 0.9998079876948159, 0.546746949802699, 0.18340913304531126, 0.26978755740650157, 0.9996755847888764, 0.9999469975241534, 0.9999343621790038, 0.9998609558896551, 0.25360932624514443, 0.7462068959854512, 0.9997815369303326, 0.9998905171360335, 0.9998267565688709, 0.9995818345537953, 0.9998261506581555, 0.9998607654390587, 0.9995087128854342, 0.9998739388872739, 0.999708347569275, 0.16102443552405288, 0.5508405853017141, 0.1509025468977805, 0.1371392471193735, 0.9997478985452689, 0.9996788481225455, 0.29068339963850076, 0.5551029086511645, 0.15417052180929164, 0.9999446206890026, 0.9998892691331523, 0.9997540008245492, 0.999761099885862, 0.9996655951488054, 0.9999150813140126, 0.9995256642231385, 0.9999221151825418, 0.9995813691514902, 0.9999588727546861, 0.9997255167687791, 0.21381427386553964, 0.7860582920066134, 0.9999423211377756, 0.9999359615919209, 0.9999061516789706, 0.9999055450800476, 0.4410943874941192, 0.5587324776562151, 0.9997968106918954, 0.0002945849414069891, 0.999624901174383, 0.9996991277865969, 0.9999030065141314, 0.9998285625998045, 0.9998241509348383, 0.999906922446499, 0.9998865122327315, 0.9997442670466854, 0.9997172034417771, 0.999879410698026, 0.20189195587253275, 0.27153642893373886, 0.5265694282321208, 0.9999096141283802, 0.9999235632560061, 0.3196701815004032, 0.680108503177152, 0.9998749538265447, 0.9995672711541923, 0.4353928013565766, 0.5641314239550038, 0.00045760173909393566, 0.9996712319487321, 0.9998021087916684, 0.9998866232383062, 0.9998525802407959, 0.9998046690477316, 0.9998667601344573, 0.9997630608402294, 0.9997091573708791, 0.9999201378758291, 0.9998500818383008, 0.9998519154524799, 0.9998810197511577, 0.9997724734307942, 0.9998797409284848, 0.9999141195990962, 0.9999621528771618, 0.9997882662617679, 0.9996342162764775, 0.9998404785287217, 0.9995772171678271, 0.9997686454312016, 0.9998908003554096, 0.9997448547751917, 0.998037553102238, 0.0018190234868206037, 0.7831750492201422, 0.21678039528975582, 0.9997752622925473, 0.9997524211304536, 0.9995873552040235, 0.15547438861506047, 0.010095739520458473, 0.17728118597925077, 0.10923590161136067, 0.010499569101276812, 0.0972219715820151, 0.0011105313472504319, 0.10055356562376638, 0.3386111035161772, 0.9998915172227115, 0.3807036887277047, 0.6192737983029303, 0.9996756236126274, 0.9998979538912346, 0.999886323073783, 0.9999375082147989, 0.023530272533393074, 0.9763195619411031, 0.9998129269150879, 0.9997643418557057, 0.9999131705908374, 0.9998703284024314, 0.9997501534779113, 0.9998894614789302, 0.9998856652991973, 0.9995869587826421, 0.9997110737930143, 0.1071044216663989, 0.002859506956385613, 0.3382479006409026, 0.09210789629513214, 0.05989078458652089, 0.19524078052210658, 6.35445990307914e-05, 0.027610128278878862, 0.010325997342503602, 0.16655039405970426, 0.9998917773232766, 0.999943276177115, 0.9998975105066829, 0.9998286400243921, 0.9927046315329662, 0.007014502772736781, 0.9996850078663615, 0.99987831688778, 0.9042688643433787, 0.09546253516425217, 0.9996888460166644, 0.9977773952117405, 0.0019893026962353125, 0.9998279914155049, 0.7375396181775443, 0.26225424059923624, 0.9996653938662349, 0.9997841574861086, 0.9998183728063831, 0.9997818253315558, 0.6353564936575764, 0.36455660984397265, 0.9999284263536744, 0.9998569980073623, 0.9995485740333868, 0.30970640549357786, 0.6899297823797719, 0.12054464144375623, 0.1836703495268303, 0.14978088732924116, 0.15856054074830572, 0.11826193155479944, 0.2690963772943284, 0.9998448711629861, 0.5778924104548399, 0.22908917589593936, 0.19281218842231473, 0.999748295618292, 0.9998235706140369, 0.9998476174780857, 0.7079237098199178, 0.2919127648062211, 0.04983420883099468, 0.9500040316389619, 0.9996736631994075, 0.14415984134110815, 0.00037118723229123435, 0.13525134776611852, 0.12829158716065786, 0.3553653765148205, 0.12889476641313113, 0.07015438690304329, 0.03758270726948748, 0.9997428573662659, 0.9997783347850953, 0.9999628453499833, 0.9999118228085438, 0.9998465063808755, 0.9998054107481572, 0.7086747451079198, 0.2912792334230779, 0.9997685992835004, 0.9998329198294087, 0.9998323535637308, 0.9994322646555823, 0.21698333115742757, 0.7829244353241733, 0.9999070556431425, 0.9998527333414265, 0.9996042414880837, 0.9999215303408168, 0.9997053798792084, 0.0002678725799542216, 0.9994325958092007, 0.9998972215949683, 0.9994601239541979, 0.9998272526379302, 0.9999015981488657, 0.9996337271592819, 0.9999404636318578, 0.9998771218732497, 0.9998154816510467, 0.9997534271832605, 0.9999095487063275, 0.9999686488466155, 0.9999565532360993, 0.9999086351651271, 0.9997001859879512, 0.9998133841485263, 0.9998999359463001, 0.9997247382766259, 0.999790138452357, 0.5002073024398641, 0.0930218120336459, 0.09565991521092562, 0.18868172724457152, 0.12238504739815065, 0.9998847192426848, 0.9998123728008798, 0.9997532812546189, 0.002035719678883257, 0.9977934597497793, 0.9997475683007332, 0.9997913608072598, 0.999651663970825, 0.9998762761809847, 0.6928801362373418, 0.1422946610564092, 0.16479076937580342, 0.9998401463423976, 0.28554201630334747, 0.00022889139583434667, 0.4928031752313484, 0.22133797977181324, 0.14001038136123814, 0.5551916485210255, 0.30474718441659615, 0.35971573473708973, 0.17905755054548697, 0.15968988342748583, 0.15467456466965634, 0.14688481425855948, 0.9998761653330941], \"Term\": [\"aboriginal\", \"abuse\", \"accused\", \"action\", \"action\", \"adelaide\", \"adelaide\", \"adelaide\", \"adelaide\", \"adelaide\", \"adelaide\", \"adelaide\", \"aged\", \"airport\", \"alan\", \"allegation\", \"alleged\", \"amid\", \"andrew\", \"animal\", \"announces\", \"appeal\", \"arrest\", \"arrested\", \"artist\", \"assault\", \"attack\", \"attack\", \"attack\", \"aussie\", \"australia\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"baby\", \"beach\", \"beach\", \"beat\", \"beat\", \"berejiklian\", \"best\", \"biden\", \"black\", \"boat\", \"body\", \"border\", \"breach\", \"briefing\", \"brisbane\", \"brisbane\", \"budget\", \"budget\", \"building\", \"bushfire\", \"bushfire\", \"bushfire\", \"bushfires\", \"business\", \"cabinet\", \"call\", \"call\", \"call\", \"call\", \"call\", \"campaign\", \"campaign\", \"campaign\", \"campaign\", \"campaign\", \"cancer\", \"care\", \"case\", \"cattle\", \"centre\", \"centre\", \"change\", \"change\", \"charge\", \"charged\", \"chief\", \"child\", \"china\", \"china\", \"china\", \"chinese\", \"chinese\", \"christmas\", \"claim\", \"climate\", \"close\", \"closure\", \"club\", \"coach\", \"coal\", \"coast\", \"commission\", \"community\", \"community\", \"community\", \"community\", \"company\", \"concern\", \"concern\", \"continues\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"council\", \"council\", \"country\", \"court\", \"court\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"crash\", \"crash\", \"cricket\", \"crisis\", \"cut\", \"cyclone\", \"daniel\", \"data\", \"david\", \"day\", \"dead\", \"dead\", \"dead\", \"death\", \"death\", \"death\", \"death\", \"decision\", \"defends\", \"doctor\", \"domestic\", \"donald\", \"drone\", \"drug\", \"drum\", \"dy\", \"early\", \"east\", \"economy\", \"election\", \"emergency\", \"england\", \"expert\", \"extended\", \"face\", \"face\", \"facebook\", \"fall\", \"family\", \"family\", \"family\", \"family\", \"family\", \"farm\", \"farmer\", \"farmer\", \"fatal\", \"fear\", \"federal\", \"female\", \"festival\", \"fight\", \"film\", \"final\", \"finance\", \"find\", \"flooding\", \"footage\", \"football\", \"france\", \"free\", \"friday\", \"funding\", \"funding\", \"future\", \"future\", \"game\", \"game\", \"george\", \"global\", \"gold\", \"good\", \"government\", \"government\", \"grand\", \"grant\", \"great\", \"green\", \"guilty\", \"health\", \"hears\", \"help\", \"help\", \"help\", \"high\", \"high\", \"hill\", \"history\", \"hit\", \"hobart\", \"home\", \"hong\", \"hospital\", \"hospital\", \"hospital\", \"hotel\", \"hour\", \"house\", \"house\", \"house\", \"house\", \"house\", \"housing\", \"human\", \"impact\", \"increase\", \"india\", \"indigenous\", \"indigenous\", \"indonesia\", \"industry\", \"injured\", \"inside\", \"international\", \"interview\", \"investigation\", \"island\", \"island\", \"island\", \"jail\", \"jailed\", \"james\", \"john\", \"johnson\", \"kid\", \"kill\", \"killed\", \"killed\", \"killing\", \"king\", \"know\", \"kohler\", \"kong\", \"korea\", \"labor\", \"land\", \"latest\", \"law\", \"lead\", \"leaf\", \"legal\", \"liberal\", \"life\", \"life\", \"life\", \"like\", \"live\", \"local\", \"lockdown\", \"long\", \"long\", \"look\", \"loss\", \"lost\", \"march\", \"mark\", \"market\", \"mean\", \"medium\", \"meet\", \"melbourne\", \"melbourne\", \"melbourne\", \"melbourne\", \"mental\", \"michael\", \"million\", \"million\", \"million\", \"minister\", \"missing\", \"monday\", \"money\", \"morning\", \"morrison\", \"mount\", \"murder\", \"music\", \"national\", \"near\", \"need\", \"need\", \"news\", \"north\", \"northern\", \"number\", \"officer\", \"officer\", \"online\", \"open\", \"open\", \"outback\", \"outbreak\", \"pandemic\", \"parent\", \"park\", \"parliament\", \"patient\", \"paul\", \"people\", \"perth\", \"perth\", \"perth\", \"peter\", \"plan\", \"player\", \"player\", \"pleads\", \"point\", \"police\", \"police\", \"police\", \"politics\", \"port\", \"power\", \"premier\", \"president\", \"price\", \"prime\", \"prince\", \"prison\", \"program\", \"project\", \"protest\", \"protester\", \"push\", \"quarantine\", \"queensland\", \"question\", \"race\", \"rain\", \"rape\", \"rate\", \"record\", \"recovery\", \"refugee\", \"refugee\", \"regional\", \"regional\", \"release\", \"released\", \"remote\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"rescue\", \"resident\", \"resident\", \"response\", \"restriction\", \"result\", \"return\", \"reveals\", \"reveals\", \"road\", \"rollout\", \"royal\", \"rugby\", \"rule\", \"rural\", \"russia\", \"sale\", \"save\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"school\", \"scott\", \"search\", \"season\", \"security\", \"security\", \"sentenced\", \"service\", \"sexual\", \"sexual\", \"share\", \"shark\", \"shark\", \"ship\", \"shooting\", \"shooting\", \"shot\", \"show\", \"smith\", \"social\", \"south\", \"south\", \"speaks\", \"sport\", \"staff\", \"star\", \"star\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"station\", \"storm\", \"storm\", \"storm\", \"story\", \"street\", \"strike\", \"student\", \"student\", \"super\", \"super\", \"survivor\", \"sydney\", \"sydney\", \"sydney\", \"sydney\", \"sydney\", \"sydney\", \"sydney\", \"sydney\", \"take\", \"talk\", \"tasmania\", \"tasmanian\", \"teen\", \"territory\", \"test\", \"test\", \"testing\", \"thousand\", \"thursday\", \"tiger\", \"time\", \"time\", \"told\", \"tourism\", \"tourist\", \"town\", \"track\", \"trade\", \"trade\", \"travel\", \"treatment\", \"tree\", \"trial\", \"truck\", \"trump\", \"tuesday\", \"turnbull\", \"united\", \"update\", \"vaccine\", \"victoria\", \"victorian\", \"video\", \"violence\", \"wall\", \"warning\", \"warns\", \"water\", \"water\", \"water\", \"water\", \"water\", \"weather\", \"wednesday\", \"week\", \"west\", \"west\", \"whale\", \"white\", \"wild\", \"win\", \"woman\", \"woman\", \"woman\", \"womens\", \"worker\", \"worker\", \"worker\", \"worker\", \"world\", \"world\", \"world\", \"year\", \"year\", \"year\", \"year\", \"year\", \"zealand\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 1, 6, 7, 9, 10, 5, 8, 2, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el487222057126375207981773025\", ldavis_el487222057126375207981773025_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el487222057126375207981773025\", ldavis_el487222057126375207981773025_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el487222057126375207981773025\", ldavis_el487222057126375207981773025_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "vis = pyLDAvis.gensim_models.prepare(topic_model=lda_model, corpus=bow_corpus, dictionary=dictionary)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some other useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237 : police : 0.036558095\n",
      "1116 : school : 0.024126064\n",
      "805 : family : 0.014821808\n",
      "313 : missing : 0.013840739\n",
      "829 : guilty : 0.012704738\n",
      "3276 : drum : 0.011469594\n",
      "1023 : announces : 0.010238418\n",
      "541 : search : 0.010200633\n",
      "111 : help : 0.01011211\n",
      "361 : northern : 0.009648915\n",
      "746 : emergency : 0.009335076\n",
      "649 : dead : 0.0093205795\n",
      "195 : crash : 0.0093162665\n",
      "284 : house : 0.009233932\n",
      "545 : finance : 0.009177075\n",
      "9637 : daniel : 0.009038304\n",
      "286 : white : 0.008198618\n",
      "2054 : budget : 0.007656283\n",
      "1072 : fatal : 0.0075939912\n",
      "593 : teen : 0.00749623\n"
     ]
    }
   ],
   "source": [
    "#get the top 20 words and their weights for a specific topic\n",
    "topic_id=1\n",
    "top_terms=20\n",
    "for wordid, score in lda_model.get_topic_terms(topic_id, top_terms):\n",
    "    print(wordid, \":\", dictionary[wordid], \":\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Utility function to get the id for a word\n",
    "\n",
    "def get_id_for_word(dictionary, word):\n",
    "    for k, v in dictionary.iteritems():\n",
    "        if (v==word):\n",
    "            return k\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 6\n",
      "8173 : trump : 0.03856796\n",
      "2232 : queensland : 0.036641274\n",
      "1619 : victoria : 0.031501103\n",
      "1363 : news : 0.020514019\n",
      "26 : record : 0.020217812\n",
      "18895 : coronavirus : 0.018310169\n",
      "1188 : market : 0.01663512\n",
      "144 : south : 0.014256183\n",
      "679 : brisbane : 0.012361713\n",
      "16 : australian : 0.011072636\n",
      "3206 : street : 0.009953073\n",
      "852 : price : 0.009940183\n",
      "1422 : interview : 0.009510273\n",
      "18896 : covid : 0.008760655\n",
      "856 : india : 0.008053296\n",
      "1416 : warning : 0.007710852\n",
      "2264 : wall : 0.00754396\n",
      "1415 : travel : 0.0075261802\n",
      "1773 : fall : 0.007395855\n",
      "3056 : video : 0.0073389453\n"
     ]
    }
   ],
   "source": [
    "top_terms=20\n",
    "index=get_id_for_word(dictionary,'market')\n",
    "for topic_id, score in lda_model.get_term_topics(index):\n",
    "    print(\"Topic:\", topic_id)\n",
    "    for wordid, score in lda_model.get_topic_terms(topic_id, top_terms):\n",
    "        print(wordid, \":\", dictionary[wordid], \":\", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading your model for re-use\n",
    "\n",
    "Building a model takes time.Once you have a stable model, you can save it to disk and reload it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to disk.\n",
    "temp_file = \"./model\"\n",
    "lda_model.save(temp_file)\n",
    "\n",
    "# Load a potentially pretrained model from disk.\n",
    "loaded_lda = lda_model.load(temp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model on unseen document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_document = 'How a Pentagon deal became an identity crisis for Google'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare any new text against the topic model, we first need to process it in the same way as we processed the input texts for the model.\n",
    "We apply the same preprocessing function and next apply the *doc2bow* function to represent it using the same vector representation as we used for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(888, 1), (1088, 1), (1922, 1), (5668, 1), (12411, 1)]\n"
     ]
    }
   ],
   "source": [
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "print(bow_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pass this representation of the unseen document into the model to compare it against all the topics.\n",
    "The next function returns in index to the topics and a similarity score for the new document. We print the scores and the topics with the top 5 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.3498535752296448\t Topic_id 8\t Topic: 0.078*\"australia\" + 0.024*\"donald\" + 0.017*\"restriction\" + 0.014*\"coronavirus\" + 0.013*\"world\"\n",
      "Score: 0.30633482336997986\t Topic_id 6\t Topic: 0.039*\"trump\" + 0.037*\"queensland\" + 0.032*\"victoria\" + 0.021*\"news\" + 0.020*\"record\"\n",
      "Score: 0.22710086405277252\t Topic_id 9\t Topic: 0.019*\"border\" + 0.017*\"north\" + 0.014*\"china\" + 0.014*\"protest\" + 0.013*\"west\"\n",
      "Score: 0.016674138605594635\t Topic_id 5\t Topic: 0.029*\"election\" + 0.023*\"health\" + 0.018*\"people\" + 0.017*\"say\" + 0.017*\"minister\"\n",
      "Score: 0.016673807054758072\t Topic_id 3\t Topic: 0.023*\"government\" + 0.020*\"coast\" + 0.017*\"national\" + 0.016*\"live\" + 0.015*\"plan\"\n",
      "Score: 0.016673140227794647\t Topic_id 0\t Topic: 0.034*\"case\" + 0.025*\"court\" + 0.023*\"police\" + 0.021*\"woman\" + 0.019*\"child\"\n",
      "Score: 0.0166724044829607\t Topic_id 1\t Topic: 0.037*\"police\" + 0.024*\"school\" + 0.015*\"family\" + 0.014*\"missing\" + 0.013*\"guilty\"\n",
      "Score: 0.0166724044829607\t Topic_id 2\t Topic: 0.019*\"victorian\" + 0.014*\"premier\" + 0.013*\"claim\" + 0.013*\"time\" + 0.012*\"speaks\"\n",
      "Score: 0.0166724044829607\t Topic_id 4\t Topic: 0.060*\"covid\" + 0.044*\"coronavirus\" + 0.019*\"open\" + 0.016*\"melbourne\" + 0.016*\"lockdown\"\n",
      "Score: 0.0166724044829607\t Topic_id 7\t Topic: 0.028*\"home\" + 0.021*\"tasmania\" + 0.018*\"business\" + 0.015*\"royal\" + 0.014*\"return\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic_id {}\\t Topic: {}\".format(score, index, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This text matches best with topic 5 although the score is not very high!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the model with a new document\n",
    "\n",
    "We can also use the unseen documents to extend our model and update the topics. This is useful when processing texts in a stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\camis\\anaconda3\\envs\\TextMining\\Lib\\site-packages\\gensim\\models\\ldamodel.py:850: RuntimeWarning: overflow encountered in exp2\n",
      "  perwordbound, np.exp2(-perwordbound), len(chunk), corpus_words\n"
     ]
    }
   ],
   "source": [
    "# Update the model by incrementally training on the new corpus.\n",
    "\n",
    "other_texts = [['computer', 'time', 'graph'],['survey', 'response', 'eps'],['human', 'system', 'computer']]\n",
    "other_corpus = [dictionary.doc2bow(text) for text in other_texts]\n",
    "\n",
    "# Update the model by incrementally training on the new corpus.\n",
    "lda_model.update(other_corpus)  # update the LDA model with additional documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
