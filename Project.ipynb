{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project \n",
    "\n",
    "## Project Description\n",
    "\n",
    "\n",
    "\n",
    "## Part 1: Data Retrieval & Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import json\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import emoji\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import vader\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "import simpletransformers\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    ")\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "### once you downloaded vader successfully you do not need to do this again.\n",
    "### You can command it out in your personal copy as I did below to skip this.\n",
    "\n",
    "# nltk.download('vader_lexicon', quiet=False)\n",
    "\n",
    "# Define file paths\n",
    "sentiment_train_file = \"Datasets/Sentiment_Analysis/sentiment_analysis.csv\"         \n",
    "sentiment_test_file = \"Datasets/Test Sets/sentiment-topic-test.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 Sentiment Analysis Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "sentiment_train_df = pd.read_csv(sentiment_train_file)\n",
    "\n",
    "# Rename the second column entries\n",
    "sentiment_train_df.iloc[:, 1] = sentiment_train_df.iloc[:, 1].replace({\n",
    "    'positive': 'POS',\n",
    "    'neutral': 'NEU',\n",
    "    'negative': 'NEG'\n",
    "})\n",
    "\n",
    "sentiment_train_df = sentiment_train_df.rename(columns={\n",
    "    'sentiment': 'Sentiment',\n",
    "    'text': 'Text'\n",
    "})[['Text', 'Sentiment']]\n",
    "\n",
    "# Remove rows where the 'text' column has more than 128 characters\n",
    "sentiment_train_df = sentiment_train_df[sentiment_train_df.iloc[:, 0].str.len() <= 128]\n",
    "\n",
    "# Save the updated training data back to the file\n",
    "sentiment_train_df.to_csv(sentiment_train_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sentiment test file into a DataFrame\n",
    "sentiment_test_df = pd.read_csv(sentiment_test_file, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "# Rename and reorganize the columns\n",
    "sentiment_test_df = sentiment_test_df.rename(columns={\n",
    "    'sentence_id': 'ID',\n",
    "    'topic': 'Relevant Topic',\n",
    "    'sentiment': 'Sentiment',\n",
    "    'sentence': 'Text'\n",
    "})[['Text', 'Sentiment', 'Relevant Topic', 'ID']]\n",
    "\n",
    "# Rename the third column entries\n",
    "sentiment_test_df.iloc[:, 1] = sentiment_test_df.iloc[:, 1].replace({\n",
    "    'positive': 'POS',\n",
    "    'neutral': 'NEU',\n",
    "    'negative': 'NEG'\n",
    "})\n",
    "\n",
    "sentiment_test_df.to_csv(sentiment_test_file, sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Processing & Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: Sentiment Analysis\n",
    "\n",
    "#### 2.1.1: Training and Testing using VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(vader_output):\n",
    "    compound_score = vader_output['compound']\n",
    "\n",
    "    if compound_score >= 0.05:\n",
    "        return 'POS'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'NEG'\n",
    "    else:\n",
    "        return 'NEU'\n",
    "\n",
    "def run_vader(textual_unit, \n",
    "              lemmatize=False, \n",
    "              parts_of_speech_to_consider=None,\n",
    "              verbose=0):\n",
    "    \"\"\"\n",
    "    Run VADER on a sentence from spacy\n",
    "    \n",
    "    :param str textual unit: a textual unit, e.g., sentence, sentences (one string)\n",
    "    (by looping over doc.sents)\n",
    "    :param bool lemmatize: If True, provide lemmas to VADER instead of words\n",
    "    :param set parts_of_speech_to_consider:\n",
    "    -None or empty set: all parts of speech are provided\n",
    "    -non-empty set: only these parts of speech are considered.\n",
    "    :param int verbose: if set to 1, information is printed\n",
    "    about input and output\n",
    "    \n",
    "    :rtype: dict\n",
    "    :return: vader output dict\n",
    "    \"\"\"\n",
    "    doc = nlp(textual_unit)\n",
    "        \n",
    "    input_to_vader = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "\n",
    "            to_add = token.text\n",
    "\n",
    "            if lemmatize:\n",
    "                to_add = token.lemma_\n",
    "\n",
    "                if to_add == '-PRON-': \n",
    "                    to_add = token.text\n",
    "\n",
    "            if parts_of_speech_to_consider:\n",
    "                if token.pos_ in parts_of_speech_to_consider:\n",
    "                    input_to_vader.append(to_add) \n",
    "            else:\n",
    "                input_to_vader.append(to_add)\n",
    "\n",
    "    scores = sia.polarity_scores(' '.join(input_to_vader))\n",
    "    \n",
    "    if verbose >= 1:\n",
    "        print()\n",
    "        print('INPUT SENTENCE', sent)\n",
    "        print('INPUT TO VADER', input_to_vader)\n",
    "        print('VADER OUTPUT', scores)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "# sentiment_train_df['Sentiment'] = sentiment_train_df['Text'].apply(get_sentiment)\n",
    "\n",
    "# sentiment_train_df.to_csv(\"Datasets/Sentiment_Analysis/vader_predicted.csv\", index=False)\n",
    "\n",
    "predicted_vader_sentiments = []\n",
    "true_vader_sentiments = []\n",
    "\n",
    "to_lemmatize = False \n",
    "pos = set()\n",
    "\n",
    "for _, sent in sentiment_train_df.iterrows():\n",
    "    tweet_info = sent['Text']\n",
    "    true_sentiment = sent['Sentiment']\n",
    "    vader_output = run_vader(tweet_info, lemmatize=to_lemmatize, verbose=0)\n",
    "    vader_label = get_sentiment(vader_output)\n",
    "\n",
    "    predicted_vader_sentiments.append(vader_label)\n",
    "    true_vader_sentiments.append(true_sentiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2.1.2 Testing using Huggingface Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pre-trained Hugging Face sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", \n",
    "                              model=\"finiteautomata/bertweet-base-sentiment-analysis\", \n",
    "                              tokenizer=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "\n",
    "# Initialize lists to store predicted sentiments and true sentiments\n",
    "predicted_model_sentiments = []\n",
    "true_model_sentiments = []\n",
    "\n",
    "# Iterate over each row in the training set\n",
    "for _, row in sentiment_train_df.iterrows():\n",
    "    # Perform sentiment analysis on the text\n",
    "    result = sentiment_pipeline(row['Text'])[0]\n",
    "    predicted_model_sentiments.append(result['label'])\n",
    "    \n",
    "    # Save the true sentiment\n",
    "    true_model_sentiments.append(row['Sentiment'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Analysis of Results\n",
    "\n",
    "### 3.1: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER Model Classification Report\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.69      0.57      0.62       122\n",
      "         NEU       0.75      0.54      0.63       187\n",
      "         POS       0.61      0.89      0.72       158\n",
      "\n",
      "    accuracy                           0.67       467\n",
      "   macro avg       0.68      0.67      0.66       467\n",
      "weighted avg       0.68      0.67      0.66       467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VADER Model Classification Report\n",
    "VADER_Classification_Report = classification_report(true_vader_sentiments, predicted_vader_sentiments)\n",
    "print(\"VADER Model Classification Report\")\n",
    "print(\"========================================\")\n",
    "print(VADER_Classification_Report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huggingface Model Classification Report\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.83      0.83      0.83         6\n",
      "         NEU       0.80      0.67      0.73         6\n",
      "         POS       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.83      0.83      0.83        18\n",
      "weighted avg       0.83      0.83      0.83        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Huggingface Model Classification Report\n",
    "Huggingface_Classification_Report = classification_report(true_model_sentiments, predicted_model_sentiments)\n",
    "print(\"Huggingface Model Classification Report\")\n",
    "print(\"========================================\")\n",
    "print(Huggingface_Classification_Report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
