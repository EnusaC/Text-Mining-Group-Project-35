{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project \n",
    "\n",
    "## Project Description\n",
    "\n",
    "\n",
    "\n",
    "## Part 1: Data Retrieval & Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import emoji\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import vader\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "import simpletransformers\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    ")\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "### once you downloaded vader successfully you do not need to do this again.\n",
    "### You can command it out in your personal copy as I did below to skip this.\n",
    "\n",
    "# nltk.download('vader_lexicon', quiet=False)\n",
    "\n",
    "# Define file paths\n",
    "sentiment_train_file = \"Datasets/Sentiment_Analysis/sentiment_analysis.csv\"         \n",
    "sentiment_test_file = \"Datasets/Test Sets/sentiment-topic-test.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 Sentiment Analysis Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(467, 2)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "sentiment_train_df = pd.read_csv(sentiment_train_file)\n",
    "\n",
    "# Rename the second column entries\n",
    "sentiment_train_df.iloc[:, 1] = sentiment_train_df.iloc[:, 1].replace({\n",
    "    'positive': 'POS',\n",
    "    'neutral': 'NEU',\n",
    "    'negative': 'NEG'\n",
    "})\n",
    "# Remove rows where the 'text' column has more than 128 characters\n",
    "sentiment_train_df = sentiment_train_df[sentiment_train_df.iloc[:, 0].str.len() <= 128]\n",
    "\n",
    "# Save the updated training data back to the file\n",
    "sentiment_train_df.to_csv(sentiment_train_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sentiment test file into a DataFrame\n",
    "sentiment_test_df = pd.read_csv(sentiment_test_file, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "# Rename and reorganize the columns\n",
    "sentiment_test_df = sentiment_test_df.rename(columns={\n",
    "    'sentence_id': 'ID',\n",
    "    'topic': 'Relevant Topic',\n",
    "    'sentiment': 'Sentiment',\n",
    "    'sentence': 'Text'\n",
    "})[['Text', 'Sentiment', 'Relevant Topic', 'ID']]\n",
    "\n",
    "# Rename the third column entries\n",
    "sentiment_test_df.iloc[:, 1] = sentiment_test_df.iloc[:, 1].replace({\n",
    "    'positive': 'POS',\n",
    "    'neutral': 'NEU',\n",
    "    'negative': 'NEG'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Processing & Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1: Sentiment Analysis using transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\", \n",
    "                            model=\"finiteautomata/bertweet-base-sentiment-analysis\", \n",
    "                            tokenizer=\"finiteautomata/bertweet-base-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store predicted sentiments and true sentiments\n",
    "predicted_sentiments = []\n",
    "true_sentiments = []\n",
    "\n",
    "# Iterate over each row in the training set\n",
    "for _, row in sentiment_test_df.iterrows():\n",
    "    # Perform sentiment analysis on the text\n",
    "    result = sentiment_analysis(row['Text'])[0]\n",
    "    predicted_sentiments.append(result['label'])\n",
    "    \n",
    "    # Save the true sentiment\n",
    "    true_sentiments.append(row['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.83      0.83      0.83         6\n",
      "         NEU       0.80      0.67      0.73         6\n",
      "         POS       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.83      0.83      0.83        18\n",
      "weighted avg       0.83      0.83      0.83        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate the classification report\n",
    "Sentiment_Analysis_Report = classification_report(true_sentiments, predicted_sentiments)\n",
    "print(Sentiment_Analysis_Report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
